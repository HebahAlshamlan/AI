{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "Cyberbullying Detection - CNN [ALANOUD].ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HebahAlshamlan/AI/blob/master/Cyberbullying_Detection_CNN_%5BALANOUD%5D.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ebS3xLHZSIfn",
        "colab_type": "text"
      },
      "source": [
        "# Cyberbullying Detection - CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yLTX4LtASIfp",
        "colab_type": "text"
      },
      "source": [
        "In this notebook we are going to implement a CNN model to detects cyberbullying in Arabic social media content.\n",
        "* The CNN model architecture is inspired by XXXX work.\n",
        "* The model settings is specified based on XXXX.\n",
        "* We will use two different word embeddings: \n",
        "    * 1- Our word embeddings trained using Gemsim library\n",
        "    * 2- Aravec word embeddigs \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n69Hp-3DSIfr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import matplotlib as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "import torch.nn.functional as F\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "pd.set_option('max_colwidth',400)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "23zsEQqWSIf3",
        "colab_type": "text"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qvUi_DYVSIf5",
        "colab_type": "text"
      },
      "source": [
        "## Loading Dataset\n",
        "\n",
        "This section of the notebook will modify the pre-processed comments' size and save the new dataset of size =11 (or any size). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gur1FMlESIf6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "outputId": "372d3215-2a97-4a96-aff0-fec455db8ca6"
      },
      "source": [
        "#This file has the comments only with empty lines\n",
        "pd.set_option('max_colwidth',400)\n",
        "# dataset = pd.read_excel('~/Dropbox/GP/GP - Deep Learning/Dataset/preprocessed_all_videos_word_embeddings_dataset_aravec_new.xlsx')\n",
        "#data = pd.read_csv('~/Dropbox/GP/GP - Deep Learning/Dataset/preprocessed_tokenized_3_videos_nan.csv')\n",
        "dataset = pd.read_excel('preprocessed_all_videos_word_embeddings_dataset_aravec_new.xlsx')\n",
        "\n",
        "print(dataset.shape)\n",
        "#print(data.shape)\n",
        "\n",
        "dataset.head()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(8083, 705)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Unnamed: 1</th>\n",
              "      <th>Unnamed: 2</th>\n",
              "      <th>Unnamed: 3</th>\n",
              "      <th>Unnamed: 4</th>\n",
              "      <th>Unnamed: 5</th>\n",
              "      <th>Unnamed: 6</th>\n",
              "      <th>Unnamed: 7</th>\n",
              "      <th>Unnamed: 8</th>\n",
              "      <th>Unnamed: 9</th>\n",
              "      <th>Unnamed: 10</th>\n",
              "      <th>Unnamed: 11</th>\n",
              "      <th>Unnamed: 12</th>\n",
              "      <th>Unnamed: 13</th>\n",
              "      <th>Unnamed: 14</th>\n",
              "      <th>Unnamed: 15</th>\n",
              "      <th>Unnamed: 16</th>\n",
              "      <th>Unnamed: 17</th>\n",
              "      <th>Unnamed: 18</th>\n",
              "      <th>Unnamed: 19</th>\n",
              "      <th>Unnamed: 20</th>\n",
              "      <th>Unnamed: 21</th>\n",
              "      <th>Unnamed: 22</th>\n",
              "      <th>Unnamed: 23</th>\n",
              "      <th>Unnamed: 24</th>\n",
              "      <th>Unnamed: 25</th>\n",
              "      <th>Unnamed: 26</th>\n",
              "      <th>Unnamed: 27</th>\n",
              "      <th>Unnamed: 28</th>\n",
              "      <th>Unnamed: 29</th>\n",
              "      <th>Unnamed: 30</th>\n",
              "      <th>Unnamed: 31</th>\n",
              "      <th>Unnamed: 32</th>\n",
              "      <th>Unnamed: 33</th>\n",
              "      <th>Unnamed: 34</th>\n",
              "      <th>Unnamed: 35</th>\n",
              "      <th>Unnamed: 36</th>\n",
              "      <th>Unnamed: 37</th>\n",
              "      <th>Unnamed: 38</th>\n",
              "      <th>Unnamed: 39</th>\n",
              "      <th>...</th>\n",
              "      <th>Unnamed: 665</th>\n",
              "      <th>Unnamed: 666</th>\n",
              "      <th>Unnamed: 667</th>\n",
              "      <th>Unnamed: 668</th>\n",
              "      <th>Unnamed: 669</th>\n",
              "      <th>Unnamed: 670</th>\n",
              "      <th>Unnamed: 671</th>\n",
              "      <th>Unnamed: 672</th>\n",
              "      <th>Unnamed: 673</th>\n",
              "      <th>Unnamed: 674</th>\n",
              "      <th>Unnamed: 675</th>\n",
              "      <th>Unnamed: 676</th>\n",
              "      <th>Unnamed: 677</th>\n",
              "      <th>Unnamed: 678</th>\n",
              "      <th>Unnamed: 679</th>\n",
              "      <th>Unnamed: 680</th>\n",
              "      <th>Unnamed: 681</th>\n",
              "      <th>Unnamed: 682</th>\n",
              "      <th>Unnamed: 683</th>\n",
              "      <th>Unnamed: 684</th>\n",
              "      <th>Unnamed: 685</th>\n",
              "      <th>Unnamed: 686</th>\n",
              "      <th>Unnamed: 687</th>\n",
              "      <th>Unnamed: 688</th>\n",
              "      <th>Unnamed: 689</th>\n",
              "      <th>Unnamed: 690</th>\n",
              "      <th>Unnamed: 691</th>\n",
              "      <th>Unnamed: 692</th>\n",
              "      <th>Unnamed: 693</th>\n",
              "      <th>Unnamed: 694</th>\n",
              "      <th>Unnamed: 695</th>\n",
              "      <th>Unnamed: 696</th>\n",
              "      <th>Unnamed: 697</th>\n",
              "      <th>Unnamed: 698</th>\n",
              "      <th>Unnamed: 699</th>\n",
              "      <th>Unnamed: 700</th>\n",
              "      <th>Unnamed: 701</th>\n",
              "      <th>Unnamed: 702</th>\n",
              "      <th>Unnamed: 703</th>\n",
              "      <th>Unnamed: 704</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>جمع</td>\n",
              "      <td>من</td>\n",
              "      <td>ابو</td>\n",
              "      <td>اله</td>\n",
              "      <td>يكف</td>\n",
              "      <td>سبد</td>\n",
              "      <td>دبل</td>\n",
              "      <td>لا</td>\n",
              "      <td>وتن</td>\n",
              "      <td>وقت</td>\n",
              "      <td>وله</td>\n",
              "      <td>فقع</td>\n",
              "      <td>جرد</td>\n",
              "      <td>وقت</td>\n",
              "      <td>ذا</td>\n",
              "      <td>مشاهير</td>\n",
              "      <td>انت</td>\n",
              "      <td>درس</td>\n",
              "      <td>نبه</td>\n",
              "      <td>ثان</td>\n",
              "      <td>شي</td>\n",
              "      <td>اول</td>\n",
              "      <td>نحف</td>\n",
              "      <td>بس</td>\n",
              "      <td>نفس</td>\n",
              "      <td>علي</td>\n",
              "      <td>ركز</td>\n",
              "      <td>حب</td>\n",
              "      <td>كثر</td>\n",
              "      <td>شكل</td>\n",
              "      <td>نبي</td>\n",
              "      <td>ما</td>\n",
              "      <td>لان</td>\n",
              "      <td>مجاديف</td>\n",
              "      <td>كسر</td>\n",
              "      <td>لك</td>\n",
              "      <td>نسل</td>\n",
              "      <td>يعن</td>\n",
              "      <td>تبي</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>جفن</td>\n",
              "      <td>ابو</td>\n",
              "      <td>هو</td>\n",
              "      <td>سعد</td>\n",
              "      <td>ولا</td>\n",
              "      <td>كوت</td>\n",
              "      <td>هذا</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>لمع</td>\n",
              "      <td>سوي</td>\n",
              "      <td>رضو</td>\n",
              "      <td>كره</td>\n",
              "      <td>ذيع</td>\n",
              "      <td>وذا</td>\n",
              "      <td>بزر</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>لمع</td>\n",
              "      <td>سوي</td>\n",
              "      <td>رضو</td>\n",
              "      <td>كره</td>\n",
              "      <td>ذيع</td>\n",
              "      <td>وذا</td>\n",
              "      <td>بزر</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>نتم</td>\n",
              "      <td>يشر</td>\n",
              "      <td>لسب</td>\n",
              "      <td>ليش</td>\n",
              "      <td>طيب</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 705 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0 Unnamed: 1 Unnamed: 2  ... Unnamed: 702 Unnamed: 703 Unnamed: 704\n",
              "0           1        جمع         من  ...          NaN          NaN          NaN\n",
              "1           0        جفن        ابو  ...          NaN          NaN          NaN\n",
              "2           1        لمع        سوي  ...          NaN          NaN          NaN\n",
              "3           1        لمع        سوي  ...          NaN          NaN          NaN\n",
              "4           0        نتم        يشر  ...          NaN          NaN          NaN\n",
              "\n",
              "[5 rows x 705 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-kt5Z-08SIgE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "d442730d-abda-42f3-e344-35f845b649df"
      },
      "source": [
        "dataset_labels = dataset['Unnamed: 0'].copy()\n",
        "dataset_comments = dataset.copy()\n",
        "dataset_comments = dataset_comments.drop(['Unnamed: 0'],axis=1)\n",
        "print(dataset_labels.shape)\n",
        "print(dataset_comments.shape)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(8083,)\n",
            "(8083, 704)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ipb20II6SIgL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "ab048fc8-a6a6-47c7-8c57-85a4c5adf8c4"
      },
      "source": [
        "print('Number of reviews before removing outliers: ', dataset_comments.shape[0])\n",
        "\n",
        "## remove any comment/labels with zero length from the dataset.\n",
        "# get indices of any reviews with length 0\n",
        "zero_idx = [ii for ii in range(dataset_comments.shape[0]) if str(dataset_comments.iloc[ii][0]) == 'nan']\n",
        "\n",
        "# remove 0-length reviews and their labels\n",
        "dataset = dataset.drop(zero_idx)\n",
        "dataset_comments = dataset_comments.drop(zero_idx)\n",
        "dataset_labels = dataset_labels.drop(zero_idx)\n",
        "\n",
        "print('Number of reviews after removing outliers: ', dataset_comments.shape[0])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of reviews before removing outliers:  8083\n",
            "Number of reviews after removing outliers:  8005\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lYGcmr1KSIgS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset_labels.to_excel('temp.xlsx')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UkjmP2ybSIgY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = pd.read_excel('temp.xlsx')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vjVlIAuESIgf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "e7a118e2-e691-4f47-ddb6-105a69964108"
      },
      "source": [
        "print(dataset.shape)\n",
        "print(dataset_labels.shape)\n",
        "print(dataset_comments.shape)\n",
        "print(data.shape)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(8005, 705)\n",
            "(8005,)\n",
            "(8005, 704)\n",
            "(8005, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wRmHG4k7SIgm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "7205dd06-2637-447f-987b-3dcf498f4d21"
      },
      "source": [
        "data.rename(columns={'Unnamed: 0': 'label'}, inplace=True)\n",
        "data.head()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   label\n",
              "0      1\n",
              "1      0\n",
              "2      1\n",
              "3      1\n",
              "4      0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "lfGQ1MweSIgq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "comments_list = []\n",
        "comments_list2 = []\n",
        "for i in range(dataset_comments.shape[0]):\n",
        "    comment = dataset_comments.iloc[i].dropna()\n",
        "    comment = comment.tolist()\n",
        "    comments_list.append(comment)\n",
        "    \n",
        "for i in range(dataset_comments.shape[0]):\n",
        "    comment = comments_list[i]\n",
        "    comment = unify_dataset_size(comment, 20)\n",
        "    comments_list2.append(comment)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "usqxp0oDSIgw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "bae9a93c-d8fd-40ad-decc-062edd89e28e"
      },
      "source": [
        "comments_df = pd.DataFrame(comments_list2)\n",
        "comments_df.head()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>كسر</td>\n",
              "      <td>لك</td>\n",
              "      <td>نسل</td>\n",
              "      <td>يعن</td>\n",
              "      <td>تبي</td>\n",
              "      <td>وش</td>\n",
              "      <td>هدم</td>\n",
              "      <td>نقد</td>\n",
              "      <td>صحب</td>\n",
              "      <td>يقل</td>\n",
              "      <td>رت</td>\n",
              "      <td>فقع</td>\n",
              "      <td>دقيق</td>\n",
              "      <td>كمل</td>\n",
              "      <td>قدر</td>\n",
              "      <td>ما</td>\n",
              "      <td>ياتسبديه</td>\n",
              "      <td>سمج</td>\n",
              "      <td>ذا</td>\n",
              "      <td>وش</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>هذا</td>\n",
              "      <td>كوت</td>\n",
              "      <td>ولا</td>\n",
              "      <td>سعد</td>\n",
              "      <td>هو</td>\n",
              "      <td>ابو</td>\n",
              "      <td>جفن</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>بزر</td>\n",
              "      <td>وذا</td>\n",
              "      <td>ذيع</td>\n",
              "      <td>كره</td>\n",
              "      <td>رضو</td>\n",
              "      <td>سوي</td>\n",
              "      <td>لمع</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>بزر</td>\n",
              "      <td>وذا</td>\n",
              "      <td>ذيع</td>\n",
              "      <td>كره</td>\n",
              "      <td>رضو</td>\n",
              "      <td>سوي</td>\n",
              "      <td>لمع</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>طيب</td>\n",
              "      <td>ليش</td>\n",
              "      <td>لسب</td>\n",
              "      <td>يشر</td>\n",
              "      <td>نتم</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    0    1    2    3    4    5    6   ...   13   14  15        16   17  18  19\n",
              "0  كسر   لك  نسل  يعن  تبي   وش  هدم  ...  كمل  قدر  ما  ياتسبديه  سمج  ذا  وش\n",
              "1  هذا  كوت  ولا  سعد   هو  ابو  جفن  ...    0    0   0         0    0   0   0\n",
              "2  بزر  وذا  ذيع  كره  رضو  سوي  لمع  ...    0    0   0         0    0   0   0\n",
              "3  بزر  وذا  ذيع  كره  رضو  سوي  لمع  ...    0    0   0         0    0   0   0\n",
              "4  طيب  ليش  لسب  يشر  نتم    0    0  ...    0    0   0         0    0   0   0\n",
              "\n",
              "[5 rows x 20 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zrIy1WDaSIg3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "3a3cfd49-42c3-405d-f53c-c41df3bef5da"
      },
      "source": [
        "data = pd.concat([comments_df, data], axis=1)\n",
        "data.head()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>كسر</td>\n",
              "      <td>لك</td>\n",
              "      <td>نسل</td>\n",
              "      <td>يعن</td>\n",
              "      <td>تبي</td>\n",
              "      <td>وش</td>\n",
              "      <td>هدم</td>\n",
              "      <td>نقد</td>\n",
              "      <td>صحب</td>\n",
              "      <td>يقل</td>\n",
              "      <td>رت</td>\n",
              "      <td>فقع</td>\n",
              "      <td>دقيق</td>\n",
              "      <td>كمل</td>\n",
              "      <td>قدر</td>\n",
              "      <td>ما</td>\n",
              "      <td>ياتسبديه</td>\n",
              "      <td>سمج</td>\n",
              "      <td>ذا</td>\n",
              "      <td>وش</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>هذا</td>\n",
              "      <td>كوت</td>\n",
              "      <td>ولا</td>\n",
              "      <td>سعد</td>\n",
              "      <td>هو</td>\n",
              "      <td>ابو</td>\n",
              "      <td>جفن</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>بزر</td>\n",
              "      <td>وذا</td>\n",
              "      <td>ذيع</td>\n",
              "      <td>كره</td>\n",
              "      <td>رضو</td>\n",
              "      <td>سوي</td>\n",
              "      <td>لمع</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>بزر</td>\n",
              "      <td>وذا</td>\n",
              "      <td>ذيع</td>\n",
              "      <td>كره</td>\n",
              "      <td>رضو</td>\n",
              "      <td>سوي</td>\n",
              "      <td>لمع</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>طيب</td>\n",
              "      <td>ليش</td>\n",
              "      <td>لسب</td>\n",
              "      <td>يشر</td>\n",
              "      <td>نتم</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     0    1    2    3    4    5    6  ...   14  15        16   17  18  19 label\n",
              "0  كسر   لك  نسل  يعن  تبي   وش  هدم  ...  قدر  ما  ياتسبديه  سمج  ذا  وش     1\n",
              "1  هذا  كوت  ولا  سعد   هو  ابو  جفن  ...    0   0         0    0   0   0     0\n",
              "2  بزر  وذا  ذيع  كره  رضو  سوي  لمع  ...    0   0         0    0   0   0     1\n",
              "3  بزر  وذا  ذيع  كره  رضو  سوي  لمع  ...    0   0         0    0   0   0     1\n",
              "4  طيب  ليش  لسب  يشر  نتم    0    0  ...    0   0         0    0   0   0     0\n",
              "\n",
              "[5 rows x 21 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z8bS0gR5SIg-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data.to_excel('all_videos_dataset_cnn_20.xlsx')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x4Aqj6-jSIhD",
        "colab_type": "text"
      },
      "source": [
        "## Numbers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "NhhhVPCgSIhE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "comment_len = []\n",
        "for i in range(dataset_comments.shape[0]):\n",
        "    comment_len.append(len(dataset_comments.iloc[i].dropna()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ApBvI2DoSIhJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "c100f29c-a450-48d8-8e3f-32361b78b5ba"
      },
      "source": [
        "comment_len.sort()\n",
        "comments_median = comment_len[len(comment_len)//2]\n",
        "comments_avg = sum(comment_len)//len(comment_len)\n",
        "\n",
        "print('\\nMedian ',comments_median)\n",
        "print('\\nMean ',comments_avg)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Median  6\n",
            "\n",
            "Mean  11\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3SuOeUvySIhN",
        "colab_type": "text"
      },
      "source": [
        "## Dataset size modification\n",
        "\n",
        "This section of the code unify the dataset size, i.e. it pad short comments with zeros, and truncate long comments. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O1KEE5c3SIhO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def unify_dataset_size(comment, size):\n",
        "    \n",
        "    if len(comment)<size:\n",
        "        return pad(comment,size)\n",
        "    elif len(comment)>size:\n",
        "        return truncate(comment,size)\n",
        "        \n",
        "    return comment"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E7ExaGELSIhT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def pad(text, size):\n",
        "    \n",
        "    comment = []\n",
        "    n = size - len(text)\n",
        "    zeros = [0]*n\n",
        "    i = len(text)-1\n",
        "    while i>=0:\n",
        "        comment.append(text[i])\n",
        "        i -=1\n",
        "        \n",
        "    for item in zeros:\n",
        "        comment.append(item) \n",
        "    \n",
        "    return comment"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s3CAQOvwSIhg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def truncate(text, size):\n",
        "    n = len(text)-size\n",
        "    comment = text[n:]\n",
        "    return comment"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WiPxv2MkSIhk",
        "colab_type": "text"
      },
      "source": [
        "## Save dataset "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q8c8VNgWSIhl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import xlsxwriter module \n",
        "import xlsxwriter \n",
        "  \n",
        "workbook = xlsxwriter.Workbook('dataset_cnn_11.xlsx') \n",
        "  \n",
        "# By default worksheet names in the spreadsheet will be  \n",
        "# Sheet1, Sheet2 etc., but we can also specify a name. \n",
        "worksheet = workbook.add_worksheet(\"My sheet\") \n",
        "\n",
        "  \n",
        "# Start from the first cell. Rows and \n",
        "# columns are zero indexed. \n",
        "row = 0\n",
        "col = 0\n",
        "  \n",
        "# Iterate over the data and write it out row by row. \n",
        "for i in range(dataset.shape[0]): \n",
        "    lis = dataset.iloc[i][0]\n",
        "    col = len(lis)\n",
        "    label = col+1\n",
        "    for word in lis:\n",
        "        worksheet.write(row, col, word) \n",
        "        col -=1\n",
        "        \n",
        "    lab = dataset.iloc[i][1]\n",
        "    if i == 7935:\n",
        "        lab = 0\n",
        "    worksheet.write(row, label, lab) \n",
        "    row += 1\n",
        "    col = 0\n",
        "    \n",
        "workbook.close() "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OkW4jD-ySIhu",
        "colab_type": "text"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8UEFLOcySIhv",
        "colab_type": "text"
      },
      "source": [
        "## Loading Word Embedding model\n",
        "\n",
        "In this section, we will impored the word embedding model we trained, and we will change the data representation to a matrix like representation. In the matrix like representation, each comment is represented by a matrix of size 11x11, each row is a word, and each word is converted to its word embeddings representation. \n",
        "* The this is saved to bb file "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z9ZQEFcMSIhv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import gensim\n",
        "from gensim.models import Word2Vec\n",
        "from gensim import corpora\n",
        "from pprint import pprint\n",
        "from gensim.utils import simple_preprocess\n",
        "from smart_open import smart_open\n",
        "import os\n",
        "from nltk import ngrams \n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zUAJCYucSIh0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "8918f899-912e-4d22-a707-4cf4ae0ec3ec"
      },
      "source": [
        "# embedding_model = Word2Vec.load(\"~/Dropbox/GP/GP - Deep Learning/Word Embeddings/Models/word2vec_sg_30_all_new.model\")\n",
        "embedding_model = Word2Vec.load(\"word2vec_sg_30_all_new.model\")"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:253: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wfDuuoavSIh6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "c7a1ddab-5327-4108-eb4d-4922ff608965"
      },
      "source": [
        "# dataset_11 = pd.read_excel('~/Dropbox/GP/GP - Deep Learning/Dataset/all_videos_dataset_cnn_20.xlsx')\n",
        "dataset_11 = pd.read_excel('all_videos_dataset_cnn_20.xlsx')\n",
        "dataset_11.head()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>كسر</td>\n",
              "      <td>لك</td>\n",
              "      <td>نسل</td>\n",
              "      <td>يعن</td>\n",
              "      <td>تبي</td>\n",
              "      <td>وش</td>\n",
              "      <td>هدم</td>\n",
              "      <td>نقد</td>\n",
              "      <td>صحب</td>\n",
              "      <td>يقل</td>\n",
              "      <td>رت</td>\n",
              "      <td>فقع</td>\n",
              "      <td>دقيق</td>\n",
              "      <td>كمل</td>\n",
              "      <td>قدر</td>\n",
              "      <td>ما</td>\n",
              "      <td>ياتسبديه</td>\n",
              "      <td>سمج</td>\n",
              "      <td>ذا</td>\n",
              "      <td>وش</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>هذا</td>\n",
              "      <td>كوت</td>\n",
              "      <td>ولا</td>\n",
              "      <td>سعد</td>\n",
              "      <td>هو</td>\n",
              "      <td>ابو</td>\n",
              "      <td>جفن</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>بزر</td>\n",
              "      <td>وذا</td>\n",
              "      <td>ذيع</td>\n",
              "      <td>كره</td>\n",
              "      <td>رضو</td>\n",
              "      <td>سوي</td>\n",
              "      <td>لمع</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>بزر</td>\n",
              "      <td>وذا</td>\n",
              "      <td>ذيع</td>\n",
              "      <td>كره</td>\n",
              "      <td>رضو</td>\n",
              "      <td>سوي</td>\n",
              "      <td>لمع</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>طيب</td>\n",
              "      <td>ليش</td>\n",
              "      <td>لسب</td>\n",
              "      <td>يشر</td>\n",
              "      <td>نتم</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0    0    1    2    3    4  ...  15        16   17  18  19 label\n",
              "0           0  كسر   لك  نسل  يعن  تبي  ...  ما  ياتسبديه  سمج  ذا  وش     1\n",
              "1           1  هذا  كوت  ولا  سعد   هو  ...   0         0    0   0   0     0\n",
              "2           2  بزر  وذا  ذيع  كره  رضو  ...   0         0    0   0   0     1\n",
              "3           3  بزر  وذا  ذيع  كره  رضو  ...   0         0    0   0   0     1\n",
              "4           4  طيب  ليش  لسب  يشر  نتم  ...   0         0    0   0   0     0\n",
              "\n",
              "[5 rows x 22 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SLZVknqaSIh-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "2b66dae6-8d62-41b1-d5e2-b36c0186b53c"
      },
      "source": [
        "dataset_11 = shuffle(dataset_11)\n",
        "dataset_11.head()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3935</th>\n",
              "      <td>3935</td>\n",
              "      <td>ذي</td>\n",
              "      <td>مثل</td>\n",
              "      <td>طلع</td>\n",
              "      <td>بنت</td>\n",
              "      <td>شرد</td>\n",
              "      <td>بنت</td>\n",
              "      <td>يوم</td>\n",
              "      <td>كل</td>\n",
              "      <td>سعد</td>\n",
              "      <td>في</td>\n",
              "      <td>حصل</td>\n",
              "      <td>غرب</td>\n",
              "      <td>شي</td>\n",
              "      <td>في</td>\n",
              "      <td>فضي</td>\n",
              "      <td>كلم</td>\n",
              "      <td>قبل</td>\n",
              "      <td>عن</td>\n",
              "      <td>بعد</td>\n",
              "      <td>يخا</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1188</th>\n",
              "      <td>1188</td>\n",
              "      <td>مو</td>\n",
              "      <td>نفع</td>\n",
              "      <td>ترا</td>\n",
              "      <td>غني</td>\n",
              "      <td>ابد</td>\n",
              "      <td>رقص</td>\n",
              "      <td>مع</td>\n",
              "      <td>رجل</td>\n",
              "      <td>اقر</td>\n",
              "      <td>قرن</td>\n",
              "      <td>بدل</td>\n",
              "      <td>اغن</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6575</th>\n",
              "      <td>6575</td>\n",
              "      <td>بله</td>\n",
              "      <td>مو</td>\n",
              "      <td>حرم</td>\n",
              "      <td>ريم</td>\n",
              "      <td>سعد</td>\n",
              "      <td>طلق</td>\n",
              "      <td>وهذ</td>\n",
              "      <td>تزج</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4595</th>\n",
              "      <td>4595</td>\n",
              "      <td>الي</td>\n",
              "      <td>حف</td>\n",
              "      <td>علي</td>\n",
              "      <td>اخت</td>\n",
              "      <td>يعط</td>\n",
              "      <td>ليك</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>613</th>\n",
              "      <td>613</td>\n",
              "      <td>سهل</td>\n",
              "      <td>لا</td>\n",
              "      <td>تكن</td>\n",
              "      <td>علم</td>\n",
              "      <td>من</td>\n",
              "      <td>علم</td>\n",
              "      <td>يوم</td>\n",
              "      <td>قيم</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      Unnamed: 0    0    1    2    3    4  ...   15   16  17   18   19 label\n",
              "3935        3935   ذي  مثل  طلع  بنت  شرد  ...  كلم  قبل  عن  بعد  يخا     0\n",
              "1188        1188   مو  نفع  ترا  غني  ابد  ...    0    0   0    0    0     0\n",
              "6575        6575  بله   مو  حرم  ريم  سعد  ...    0    0   0    0    0     1\n",
              "4595        4595  الي   حف  علي  اخت  يعط  ...    0    0   0    0    0     1\n",
              "613          613  سهل   لا  تكن  علم   من  ...    0    0   0    0    0     0\n",
              "\n",
              "[5 rows x 22 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8hwU8Bo_SIiD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ad924c3b-6471-42df-f3b7-f1917ef05162"
      },
      "source": [
        "dataset_11_label = dataset_11['label']\n",
        "dataset_11_label = dataset_11_label.to_numpy()\n",
        "print(dataset_11_label.shape)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(8005,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p-oj6j3PSIiK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset_11_comment = dataset_11['Unnamed: 0'].copy() \n",
        "dataset_11 = dataset_11.drop(['Unnamed: 0', 'label'], axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iPQAboxRSIiQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(dataset_11.shape[0]):\n",
        "    comment = dataset_11.iloc[i].dropna()\n",
        "    comment = comment.tolist()\n",
        "    dataset_11_comment.iloc[i] = comment"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2G4ykxVgSIiU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "5b617270-ee82-4e9d-e74d-15c753e3635a"
      },
      "source": [
        "dataset_11_comment = pd.DataFrame(dataset_11_comment)\n",
        "dataset_11_comment.head()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3935</th>\n",
              "      <td>[ذي, مثل, طلع, بنت, شرد, بنت, يوم, كل, سعد, في, حصل, غرب, شي, في, فضي, كلم, قبل, عن, بعد, يخا]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1188</th>\n",
              "      <td>[مو, نفع, ترا, غني, ابد, رقص, مع, رجل, اقر, قرن, بدل, اغن, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6575</th>\n",
              "      <td>[بله, مو, حرم, ريم, سعد, طلق, وهذ, تزج, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4595</th>\n",
              "      <td>[الي, حف, علي, اخت, يعط, ليك, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>613</th>\n",
              "      <td>[سهل, لا, تكن, علم, من, علم, يوم, قيم, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                          Unnamed: 0\n",
              "3935  [ذي, مثل, طلع, بنت, شرد, بنت, يوم, كل, سعد, في, حصل, غرب, شي, في, فضي, كلم, قبل, عن, بعد, يخا]\n",
              "1188              [مو, نفع, ترا, غني, ابد, رقص, مع, رجل, اقر, قرن, بدل, اغن, 0, 0, 0, 0, 0, 0, 0, 0]\n",
              "6575                     [بله, مو, حرم, ريم, سعد, طلق, وهذ, تزج, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
              "4595                         [الي, حف, علي, اخت, يعط, ليك, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
              "613                       [سهل, لا, تكن, علم, من, علم, يوم, قيم, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BqtJyB_kSIiZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "826e75b0-95ca-49d1-985f-08a94425b22b"
      },
      "source": [
        "print(dataset_11_comment.shape)\n",
        "print(dataset_11_label.shape)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(8005, 1)\n",
            "(8005,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XDUFmsTjSIie",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "cf9553b1-8738-42a3-8f96-d5f073d72779"
      },
      "source": [
        "\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split\n",
        " \n",
        "train_x, remaining_x, train_y, remaining_y = train_test_split(dataset_11_comment, dataset_11_label, \n",
        "                                                    test_size=0.20, random_state=42, shuffle =False)\n",
        "\n",
        "test_idx = int(remaining_x.shape[0]*0.5)\n",
        "val_x, test_x = remaining_x[:test_idx], remaining_x[test_idx:]\n",
        "val_y, test_y = remaining_y[:test_idx], remaining_y[test_idx:]\n",
        "\n",
        "## print out the shapes of your resultant feature data\n",
        "print(\"\\t\\t\\tFeature Shapes:\")\n",
        "print(\"Train set: \\t\\t{}\".format(train_x.shape), \n",
        "      \"\\nValidation set: \\t{}\".format(val_x.shape),\n",
        "      \"\\nTest set: \\t\\t{}\".format(test_x.shape))\n",
        "\n",
        "train_y = np.asarray(train_y)\n",
        "val_y = np.asarray(val_y)\n",
        "test_y = np.asarray(test_y)\n",
        "\n",
        "print(train_y.shape)\n",
        "print(val_y.shape)\n",
        "print(test_y.shape)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\t\t\tFeature Shapes:\n",
            "Train set: \t\t(6404, 1) \n",
            "Validation set: \t(800, 1) \n",
            "Test set: \t\t(801, 1)\n",
            "(6404,)\n",
            "(800,)\n",
            "(801,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJ_9x3nZSIij",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "outputId": "b14fae79-2432-42e9-d619-56628c2464bc"
      },
      "source": [
        "X_train.iloc[0][0]"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-44-5f05a5c1341b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l6dkv7LmSIio",
        "colab_type": "text"
      },
      "source": [
        "## Create image like comments representaion\n",
        "\n",
        "Here we will change the comments representation from list of words to a matrix representation. Each row of the matrix is a word, and it is represented using word embeddings with dim = 150 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3raZFb1DSIio",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embed_vocab = []\n",
        "for x in embedding_model.wv.vocab:\n",
        "    embed_vocab.append(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7eXUw-mjSIiu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import difflib\n",
        "import random\n",
        "\n",
        "def get_most_sim_word(word):\n",
        "    res = difflib.get_close_matches(word,embed_vocab,n=1)\n",
        "    if (len(res)==0):\n",
        "        idx = random.randrange(len(embed_vocab))\n",
        "        res = embed_vocab[idx]\n",
        "    return res"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z1NyGR6zSIiy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sen_to_matrix(sen, dim):\n",
        "    \n",
        "    matrix = np.empty([len(sen), dim])\n",
        "    i = 0    \n",
        "    for word in sen:\n",
        "        if word == 0:\n",
        "            rep = [0] * dim\n",
        "        else:\n",
        "            try:\n",
        "                rep = embedding_model[word]\n",
        "            except KeyError:\n",
        "                sim_word = get_most_sim_word(word)\n",
        "                rep = embedding_model[sim_word]\n",
        "                if(len(rep)==1):\n",
        "                    rep = rep[0]\n",
        "        \n",
        "        j=0        \n",
        "        for d in rep:\n",
        "            matrix[i][j] = d\n",
        "            j += 1 \n",
        "        i += 1\n",
        "    \n",
        "    return matrix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AcLbmSSrSIi4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "f1b1edfb-a72e-45cc-a790-1526f0cfc40e"
      },
      "source": [
        "X_train_np = np.empty([train_x.shape[0]*20, 30])\n",
        "\n",
        "for i in range(train_x.shape[0]):\n",
        "    index = i*20\n",
        "    com = train_x.iloc[i][0]\n",
        "    mat = sen_to_matrix(com, 30)\n",
        "    X_train_np[index:index+20] = pd.DataFrame(mat)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  # Remove the CWD from sys.path while we load stuff.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  del sys.path[0]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZYodRSerSIi-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "b12ff3ce-cf7f-4449-daf0-04d2cec8b6ea"
      },
      "source": [
        "X_val_np = np.empty([val_x.shape[0]*20, 30])\n",
        "\n",
        "for i in range(val_x.shape[0]):\n",
        "    index = i*20\n",
        "    com = val_x.iloc[i][0]\n",
        "    mat = sen_to_matrix(com, 30)\n",
        "    X_val_np[index:index+20] = pd.DataFrame(mat)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  # Remove the CWD from sys.path while we load stuff.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  del sys.path[0]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HS7cltbuSIjD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "63addc1b-a1fb-4a45-9764-9e18966d32fb"
      },
      "source": [
        "X_test_np = np.empty([test_x.shape[0]*20, 30])\n",
        "\n",
        "for i in range(test_x.shape[0]):\n",
        "    index = i*20\n",
        "    com = test_x.iloc[i][0]\n",
        "    mat = sen_to_matrix(com, 30)\n",
        "    X_test_np[index:index+20] = pd.DataFrame(mat)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  # Remove the CWD from sys.path while we load stuff.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  del sys.path[0]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Ms8ZabMSIjJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 249
        },
        "outputId": "2f5f7e41-9259-4952-df9d-7f919fc6ba25"
      },
      "source": [
        "print(X_train_np.shape[0]/20)\n",
        "print(X_test_np.shape[0]/20)\n",
        "print(X_train.shape[0])\n",
        "print(X_test.shape[0])"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6404.0\n",
            "801.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-39-0d65f76f7f13>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_np\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_np\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ggIJRO1sSIjP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train = np.array(train_y)\n",
        "y_val = np.array(val_y)\n",
        "y_test = np.array(test_y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R5ELD9j3SIjX",
        "colab_type": "text"
      },
      "source": [
        "### Save"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o7MZQxpVSIjd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class CommentsDatasetTrain(Dataset):\n",
        "    def __init__(self):\n",
        "        self.len = X_train_np.shape[0]//20\n",
        "        self.x_data = torch.from_numpy(X_train_np)\n",
        "        self.y_data = torch.from_numpy(y_train)\n",
        "        \n",
        "    def __getitem__(self, index):\n",
        "        return self.x_data[index:index+20], self.y_data[index]\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.len"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2gYe6NvZSIji",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CommentsDatasetVal(Dataset):\n",
        "    def __init__(self):\n",
        "        self.len = X_val_np.shape[0]//20\n",
        "        self.x_data = torch.from_numpy(X_val_np)\n",
        "        self.y_data = torch.from_numpy(y_val)\n",
        "        \n",
        "    def __getitem__(self, index):\n",
        "        return self.x_data[index:index+20], self.y_data[index]\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.len"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "impetit1SIjo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CommentsDatasetTest(Dataset):\n",
        "    def __init__(self):\n",
        "        self.len = X_test_np.shape[0]//20\n",
        "        self.x_data = torch.from_numpy(X_test_np)\n",
        "        self.y_data = torch.from_numpy(y_test)\n",
        "            \n",
        "    def __getitem__(self, index):\n",
        "        return self.x_data[index:index+20], self.y_data[index]\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.len"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O5YoOXfqSIjz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 64"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o0O7z08ESIj6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset_v1_train = CommentsDatasetTrain()\n",
        "\n",
        "train_loader = DataLoader(dataset=dataset_v1_train,\n",
        "                         batch_size= batch_size,\n",
        "                         num_workers=0,\n",
        "                          drop_last=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "viFVW4ysSIkA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset_v1_val = CommentsDatasetVal()\n",
        "\n",
        "val_loader = DataLoader(dataset=dataset_v1_val,\n",
        "                         batch_size=batch_size,\n",
        "                         num_workers=0,\n",
        "                        drop_last=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ld2LkysSIkI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset_v1_test = CommentsDatasetTest()\n",
        "\n",
        "test_loader = DataLoader(dataset=dataset_v1_test,\n",
        "                         batch_size=batch_size,\n",
        "                         num_workers=0,\n",
        "                         drop_last=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "du5J4lFASIkQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "648f9b91-d95a-48be-9736-00f997e20965"
      },
      "source": [
        "i = 0\n",
        "for data, target in train_loader:\n",
        "    i += 1\n",
        "    print(data.shape)\n",
        "    print(target.shape)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([64, 20, 30])\n",
            "torch.Size([64])\n",
            "torch.Size([64, 20, 30])\n",
            "torch.Size([64])\n",
            "torch.Size([64, 20, 30])\n",
            "torch.Size([64])\n",
            "torch.Size([64, 20, 30])\n",
            "torch.Size([64])\n",
            "torch.Size([64, 20, 30])\n",
            "torch.Size([64])\n",
            "torch.Size([64, 20, 30])\n",
            "torch.Size([64])\n",
            "torch.Size([64, 20, 30])\n",
            "torch.Size([64])\n",
            "torch.Size([64, 20, 30])\n",
            "torch.Size([64])\n",
            "torch.Size([64, 20, 30])\n",
            "torch.Size([64])\n",
            "torch.Size([64, 20, 30])\n",
            "torch.Size([64])\n",
            "torch.Size([64, 20, 30])\n",
            "torch.Size([64])\n",
            "torch.Size([64, 20, 30])\n",
            "torch.Size([64])\n",
            "torch.Size([64, 20, 30])\n",
            "torch.Size([64])\n",
            "torch.Size([64, 20, 30])\n",
            "torch.Size([64])\n",
            "torch.Size([64, 20, 30])\n",
            "torch.Size([64])\n",
            "torch.Size([64, 20, 30])\n",
            "torch.Size([64])\n",
            "torch.Size([64, 20, 30])\n",
            "torch.Size([64])\n",
            "torch.Size([64, 20, 30])\n",
            "torch.Size([64])\n",
            "torch.Size([64, 20, 30])\n",
            "torch.Size([64])\n",
            "torch.Size([64, 20, 30])\n",
            "torch.Size([64])\n",
            "torch.Size([64, 20, 30])\n",
            "torch.Size([64])\n",
            "torch.Size([64, 20, 30])\n",
            "torch.Size([64])\n",
            "torch.Size([64, 20, 30])\n",
            "torch.Size([64])\n",
            "torch.Size([64, 20, 30])\n",
            "torch.Size([64])\n",
            "torch.Size([64, 20, 30])\n",
            "torch.Size([64])\n",
            "torch.Size([64, 20, 30])\n",
            "torch.Size([64])\n",
            "torch.Size([64, 20, 30])\n",
            "torch.Size([64])\n",
            "torch.Size([64, 20, 30])\n",
            "torch.Size([64])\n",
            "torch.Size([64, 20, 30])\n",
            "torch.Size([64])\n",
            "torch.Size([64, 20, 30])\n",
            "torch.Size([64])\n",
            "torch.Size([64, 20, 30])\n",
            "torch.Size([64])\n",
            "torch.Size([64, 20, 30])\n",
            "torch.Size([64])\n",
            "torch.Size([64, 20, 30])\n",
            "torch.Size([64])\n",
            "torch.Size([64, 20, 30])\n",
            "torch.Size([64])\n",
            "torch.Size([64, 20, 30])\n",
            "torch.Size([64])\n",
            "torch.Size([64, 20, 30])\n",
            "torch.Size([64])\n",
            "torch.Size([64, 20, 30])\n",
            "torch.Size([64])\n",
            "torch.Size([64, 20, 30])\n",
            "torch.Size([64])\n",
            "torch.Size([64, 20, 30])\n",
            "torch.Size([64])\n",
            "torch.Size([64, 20, 30])\n",
            "torch.Size([64])\n",
            "torch.Size([64, 20, 30])\n",
            "torch.Size([64])\n",
            "torch.Size([64, 20, 30])\n",
            "torch.Size([64])\n",
            "torch.Size([64, 20, 30])\n",
            "torch.Size([64])\n",
            "torch.Size([64, 20, 30])\n",
            "torch.Size([64])\n",
            "torch.Size([64, 20, 30])\n",
            "torch.Size([64])\n",
            "torch.Size([64, 20, 30])\n",
            "torch.Size([64])\n",
            "torch.Size([64, 20, 30])\n",
            "torch.Size([64])\n",
            "torch.Size([64, 20, 30])\n",
            "torch.Size([64])\n",
            "torch.Size([64, 20, 30])\n",
            "torch.Size([64])\n",
            "torch.Size([64, 20, 30])\n",
            "torch.Size([64])\n",
            "torch.Size([64, 20, 30])\n",
            "torch.Size([64])\n",
            "torch.Size([64, 20, 30])\n",
            "torch.Size([64])\n",
            "torch.Size([64, 20, 30])\n",
            "torch.Size([64])\n",
            "torch.Size([64, 20, 30])\n",
            "torch.Size([64])\n",
            "torch.Size([64, 20, 30])\n",
            "torch.Size([64])\n",
            "torch.Size([64, 20, 30])\n",
            "torch.Size([64])\n",
            "torch.Size([64, 20, 30])\n",
            "torch.Size([64])\n",
            "torch.Size([64, 20, 30])\n",
            "torch.Size([64])\n",
            "torch.Size([64, 20, 30])\n",
            "torch.Size([64])\n",
            "torch.Size([64, 20, 30])\n",
            "torch.Size([64])\n",
            "torch.Size([64, 20, 30])\n",
            "torch.Size([64])\n",
            "torch.Size([64, 20, 30])\n",
            "torch.Size([64])\n",
            "torch.Size([64, 20, 30])\n",
            "torch.Size([64])\n",
            "torch.Size([64, 20, 30])\n",
            "torch.Size([64])\n",
            "torch.Size([64, 20, 30])\n",
            "torch.Size([64])\n",
            "torch.Size([64, 20, 30])\n",
            "torch.Size([64])\n",
            "torch.Size([64, 20, 30])\n",
            "torch.Size([64])\n",
            "torch.Size([64, 20, 30])\n",
            "torch.Size([64])\n",
            "torch.Size([64, 20, 30])\n",
            "torch.Size([64])\n",
            "torch.Size([64, 20, 30])\n",
            "torch.Size([64])\n",
            "torch.Size([64, 20, 30])\n",
            "torch.Size([64])\n",
            "torch.Size([64, 20, 30])\n",
            "torch.Size([64])\n",
            "torch.Size([64, 20, 30])\n",
            "torch.Size([64])\n",
            "torch.Size([64, 20, 30])\n",
            "torch.Size([64])\n",
            "torch.Size([64, 20, 30])\n",
            "torch.Size([64])\n",
            "torch.Size([64, 20, 30])\n",
            "torch.Size([64])\n",
            "torch.Size([64, 20, 30])\n",
            "torch.Size([64])\n",
            "torch.Size([64, 20, 30])\n",
            "torch.Size([64])\n",
            "torch.Size([64, 20, 30])\n",
            "torch.Size([64])\n",
            "torch.Size([64, 20, 30])\n",
            "torch.Size([64])\n",
            "torch.Size([64, 20, 30])\n",
            "torch.Size([64])\n",
            "torch.Size([64, 20, 30])\n",
            "torch.Size([64])\n",
            "torch.Size([64, 20, 30])\n",
            "torch.Size([64])\n",
            "torch.Size([64, 20, 30])\n",
            "torch.Size([64])\n",
            "torch.Size([64, 20, 30])\n",
            "torch.Size([64])\n",
            "torch.Size([64, 20, 30])\n",
            "torch.Size([64])\n",
            "torch.Size([64, 20, 30])\n",
            "torch.Size([64])\n",
            "torch.Size([64, 20, 30])\n",
            "torch.Size([64])\n",
            "torch.Size([64, 20, 30])\n",
            "torch.Size([64])\n",
            "torch.Size([64, 20, 30])\n",
            "torch.Size([64])\n",
            "torch.Size([64, 20, 30])\n",
            "torch.Size([64])\n",
            "torch.Size([64, 20, 30])\n",
            "torch.Size([64])\n",
            "torch.Size([64, 20, 30])\n",
            "torch.Size([64])\n",
            "torch.Size([64, 20, 30])\n",
            "torch.Size([64])\n",
            "torch.Size([64, 20, 30])\n",
            "torch.Size([64])\n",
            "torch.Size([64, 20, 30])\n",
            "torch.Size([64])\n",
            "torch.Size([64, 20, 30])\n",
            "torch.Size([64])\n",
            "torch.Size([64, 20, 30])\n",
            "torch.Size([64])\n",
            "torch.Size([64, 20, 30])\n",
            "torch.Size([64])\n",
            "torch.Size([64, 20, 30])\n",
            "torch.Size([64])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4EU5_r_RSIkX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "outputId": "56ad409b-840b-470e-b7ce-39ed627010de"
      },
      "source": [
        "i = 0\n",
        "for data, target in test_loader:\n",
        "    i += 1\n",
        "    print(data.shape)\n",
        "    print(target.shape)\n",
        "print(i)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([64, 20, 30])\n",
            "torch.Size([64])\n",
            "torch.Size([64, 20, 30])\n",
            "torch.Size([64])\n",
            "torch.Size([64, 20, 30])\n",
            "torch.Size([64])\n",
            "torch.Size([64, 20, 30])\n",
            "torch.Size([64])\n",
            "torch.Size([64, 20, 30])\n",
            "torch.Size([64])\n",
            "torch.Size([64, 20, 30])\n",
            "torch.Size([64])\n",
            "torch.Size([64, 20, 30])\n",
            "torch.Size([64])\n",
            "torch.Size([64, 20, 30])\n",
            "torch.Size([64])\n",
            "torch.Size([64, 20, 30])\n",
            "torch.Size([64])\n",
            "torch.Size([64, 20, 30])\n",
            "torch.Size([64])\n",
            "torch.Size([64, 20, 30])\n",
            "torch.Size([64])\n",
            "torch.Size([64, 20, 30])\n",
            "torch.Size([64])\n",
            "12\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q3SBMV5RSIkc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "outputId": "bb37ed82-6b2a-47be-8c83-ef6626b2efe4"
      },
      "source": [
        "i = 0\n",
        "for data, target in val_loader:\n",
        "    i += 1\n",
        "    print(data.shape)\n",
        "    print(target.shape)\n",
        "print(i)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([64, 20, 30])\n",
            "torch.Size([64])\n",
            "torch.Size([64, 20, 30])\n",
            "torch.Size([64])\n",
            "torch.Size([64, 20, 30])\n",
            "torch.Size([64])\n",
            "torch.Size([64, 20, 30])\n",
            "torch.Size([64])\n",
            "torch.Size([64, 20, 30])\n",
            "torch.Size([64])\n",
            "torch.Size([64, 20, 30])\n",
            "torch.Size([64])\n",
            "torch.Size([64, 20, 30])\n",
            "torch.Size([64])\n",
            "torch.Size([64, 20, 30])\n",
            "torch.Size([64])\n",
            "torch.Size([64, 20, 30])\n",
            "torch.Size([64])\n",
            "torch.Size([64, 20, 30])\n",
            "torch.Size([64])\n",
            "torch.Size([64, 20, 30])\n",
            "torch.Size([64])\n",
            "torch.Size([64, 20, 30])\n",
            "torch.Size([64])\n",
            "12\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xZPisZHFSIkg",
        "colab_type": "text"
      },
      "source": [
        "## CNN model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7zD2u0WSSIkg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "f7cb16ab-b3f3-499b-bdd1-c05f152a0f01"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# define the CNN architecture\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        \n",
        "        # convolutional layer (sees 20x30x1 image tensor)\n",
        "        self.conv1 = nn.Conv2d(32, 32, 3, padding=1)\n",
        "        # convolutional layer (sees 10x15x32 tensor)\n",
        "        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n",
        "        \n",
        "        # convolutional layer (sees 8x8x32 tensor)\n",
        "        #self.conv3 = nn.Conv2d(32, 64, 3, padding=1)\n",
        "        \n",
        "        # max pooling layer\n",
        "        self.pool = nn.AvgPool2d(2, 2)\n",
        "        \n",
        "        # linear layer (5 * 7 * 32 -> 8000)\n",
        "        self.fc1 = nn.Linear( 1120 , 256)\n",
        "        \n",
        "        # linear layer (50 -> 10)\n",
        "        self.fc2 = nn.Linear(256, 1)\n",
        "        # dropout layer (p=0.25)\n",
        "        \n",
        "        self.dropout = nn.Dropout(0.20)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \n",
        "        # add sequence of convolutional and max pooling layers\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        \n",
        "        x = self.dropout(x)\n",
        "        # x = self.pool(F.relu(self.conv3(x)))\n",
        "        # flatten image input\n",
        "        x_s = x.view(x.shape[0],-1)\n",
        "\n",
        "        # add dropout layer\n",
        "        #x = self.dropout(x)\n",
        "        # add 1st hidden layer, with relu activation function\n",
        "        x_s = F.relu(self.fc1(x_s))\n",
        "        # add dropout layer\n",
        "        x_s = self.dropout(x_s)\n",
        "        # add 2nd hidden layer, with relu activation function\n",
        "        #x = self.fc1(x)\n",
        "        out = self.fc2(x_s)\n",
        "        return F.sigmoid(out)\n",
        "\n",
        "# create a complete CNN\n",
        "model = CNN()\n",
        "print(model)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CNN(\n",
            "  (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "  (fc1): Linear(in_features=1120, out_features=256, bias=True)\n",
            "  (fc2): Linear(in_features=256, out_features=1, bias=True)\n",
            "  (dropout): Dropout(p=0.2, inplace=False)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VOjUtRdeSIkl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "406dbb03-274c-4dd5-cf3d-6e1b9151035a"
      },
      "source": [
        "model.parameters()"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<generator object Module.parameters at 0x7f211b7aef68>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S35QICIrSIkq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "# specify loss function (categorical cross-entropy)\n",
        "criterion = nn.BCELoss()\n",
        "\n",
        "# specify optimizer\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.003)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "--uJDM96SIkz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# number of epochs to train the model\n",
        "def training(model,e):\n",
        "    n_epochs = e\n",
        "    valid_losses = []\n",
        "    train_losses = []\n",
        "    valid_loss_min = np.Inf # track change in validation loss\n",
        "\n",
        "    for epoch in range(1, n_epochs+1):\n",
        "\n",
        "#         if epoch > 0 and epoch % (2) == 0:\n",
        "#         #if epoch > 0:\n",
        "#             print(\"epoch = %6d\" % epoch, end=\"\")\n",
        "#             print(\"  batch loss = %7.4f\" % loss.item(), end=\"\")\n",
        "#             acc = akkuracy(model, data, target)\n",
        "#             print(\"  accuracy = %0.2f%%\" % acc)\n",
        "        \n",
        "    # keep track of training and validation loss\n",
        "        train_loss = 0.0\n",
        "        valid_loss = 0.0\n",
        "    \n",
        "    ###################\n",
        "    # train the model #\n",
        "    ###################\n",
        "        j =0\n",
        "        model.train()\n",
        "        for data, target in train_loader:\n",
        "        # move tensors to GPU if CUDA is available\n",
        "#         if train_on_gpu:\n",
        "#             data, target = data.cuda(), target.cuda()\n",
        "        # clear the gradients of all optimized variables\n",
        "\n",
        "            data = torch.tensor(data).type('torch.FloatTensor')\n",
        "            target = torch.tensor(target).type('torch.FloatTensor')\n",
        "            optimizer.zero_grad()\n",
        "        # forward pass: compute predicted outputs by passing inputs to the model\n",
        "        \n",
        "#         print('batch ',j)\n",
        "#         #try:\n",
        "#         output = [0] * 32\n",
        "#         for i in range(32):\n",
        "#             print(i)\n",
        "#             output[i] = model(data[i].view(1,1,11,150))\n",
        "\n",
        "#         except RuntimeError:\n",
        "#             outout = [0] * 9\n",
        "#             for i in range(9):\n",
        "#                 outout[i] = model(data[i].view(1,1,11,150))\n",
        "            \n",
        "            \n",
        "            output = model(data.view(batch_size,1,20,30))\n",
        "        \n",
        "            \n",
        "        # calculate the batch loss\n",
        "\n",
        "#             t = []\n",
        "#             for i in range(target.shape[0]):\n",
        "#                 if target[i] == 1:\n",
        "#                     t.append([0,1])\n",
        "#                 else:\n",
        "#                     t.append([1,0])\n",
        "#             t = torch.FloatTensor(t)\n",
        "        \n",
        "            loss = criterion(output, target)\n",
        "            # backward pass: compute gradient of the loss with respect to model parameters\n",
        "            loss.backward()\n",
        "            # perform a single optimization step (parameter update)\n",
        "            optimizer.step()\n",
        "            # update training loss\n",
        "            train_loss += loss.item()*data.size(0)\n",
        "        \n",
        "    ######################    \n",
        "    # validate the model #\n",
        "    ######################\n",
        "        model.eval()\n",
        "        for data, target in val_loader:\n",
        "        # move tensors to GPU if CUDA is available\n",
        "#         if train_on_gpu:\n",
        "#             data, target = data.cuda(), target.cuda()\n",
        "        # forward pass: compute predicted outputs by passing inputs to the model\n",
        "            data = torch.tensor(data).type('torch.FloatTensor')\n",
        "            target = torch.tensor(target).type('torch.FloatTensor')\n",
        "        \n",
        "            output = model(data.view(batch_size,1,20,30))\n",
        "        \n",
        "            \n",
        "        # calculate the batch loss\n",
        "\n",
        "#             t = []\n",
        "#             for i in range(target.shape[0]):\n",
        "#                 if target[i] == 1:\n",
        "#                     t.append([0,1])\n",
        "#                 else:\n",
        "#                     t.append([1,0])\n",
        "#             t = torch.FloatTensor(t)\n",
        "        \n",
        "            loss = criterion(output, target)\n",
        "\n",
        "            # update average validation loss \n",
        "            valid_loss += loss.item()*data.size(0)\n",
        "    \n",
        "    # calculate average losses\n",
        "        train_loss = train_loss/len(train_loader.sampler)\n",
        "        valid_loss = valid_loss/len(val_loader.sampler)\n",
        "    \n",
        "        if epoch > 0 and epoch % (n_epochs/10) == 0:\n",
        "            # print training/validation statistics \n",
        "            print('Epoch: {} \\tTraining Loss: {} \\tValidation Loss: {}'.format(\n",
        "                 epoch, train_loss, valid_loss))\n",
        "            train_losses.append(train_loss)\n",
        "            valid_losses.append(valid_loss)\n",
        "    \n",
        "    # save model if validation loss has decreased\n",
        "#     if valid_loss <= valid_loss_min:\n",
        "#         print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
        "#         valid_loss_min,\n",
        "#         valid_loss))\n",
        "#         torch.save(model.state_dict(), 'model_cifar.pt')\n",
        "#         valid_loss_min = valid_loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ly65TtRMSIk8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def testing(model):\n",
        "    outputs_list = []\n",
        "    labels_list = []\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    for data, target in test_loader:\n",
        "\n",
        "        data = torch.tensor(data).type('torch.FloatTensor')\n",
        "        target = torch.tensor(target).type('torch.FloatTensor')\n",
        "        \n",
        "        b = data.shape[0]\n",
        "        pred_y = model(data.view(b,1,20,30))\n",
        "            \n",
        "#         pred_y = []\n",
        "#         for i in range(batch_size):\n",
        "#             if output[i][0]>0.5:\n",
        "#                 pred_y.append(0)\n",
        "#             else:\n",
        "#                 pred_y.append(1)\n",
        "        for i in range(batch_size):\n",
        "            outputs_list.append(pred_y[i].item())\n",
        "            labels_list.append(target[i].item())\n",
        "        \n",
        "    return outputs_list, labels_list        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c5gQPiyISIlC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "outputId": "5e7f1f24-e05b-4a57-d8ba-efc075678919"
      },
      "source": [
        "j=0\n",
        "for i in range(len(outputs_list)):\n",
        "    if outputs_list[i]>=0.5:\n",
        "        j+=1\n",
        "print()"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-58-b632e531830d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0moutputs_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m>=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mj\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'outputs_list' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SOJg1374SIlG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def akkuracy(model, data_x, data_y):\n",
        "    # data_x and data_y are numpy array-of-arrays matrices\n",
        "    X = torch.Tensor(data_x)\n",
        "    Y = torch.Tensor(data_y)   # a Tensor of 0s and 1s\n",
        "    b = data_x.shape[0]\n",
        "    oupt = model(X.view(batch_size,1,20,30))            # a Tensor of floats\n",
        "    pred_y = []\n",
        "    for i in range(batch_size):\n",
        "        if oupt[i]>0.5:\n",
        "            pred_y.append(1)\n",
        "        else:\n",
        "            pred_y.append(0)\n",
        "   \n",
        "            \n",
        "    # pred_y = oupt >= 0.5       # a Tensor of 0s and 1s\n",
        "    pred_y = torch.Tensor(pred_y)\n",
        "    print(pred_y.shape)\n",
        "    num_correct = torch.sum(Y==pred_y)  # a Tensor\n",
        "    \n",
        "    target_names= ['Not Cyberbullying', 'Cyberbullying']\n",
        "\n",
        "    print(confusion_matrix (pred_y, data_y))\n",
        "    print(classification_report(pred_y, data_y, target_names=target_names))\n",
        "    print(\"Accuracy: \",accuracy_score(pred_y, data_y))\n",
        "    \n",
        "    acc = (num_correct.item() * 100.0 / len(data_y))  # scalar\n",
        "    return acc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A8GAQ05ISIlL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import confusion_matrix \n",
        "import random\n",
        "\n",
        "\n",
        "def metrics(outputs_list_n, labels_list_n):\n",
        "    \n",
        "    y_pred = []\n",
        "    y_true = labels_list_n\n",
        "\n",
        "    for i in range(len(outputs_list_n)):\n",
        "        if(outputs_list_n[i]>=0.5):\n",
        "            y_pred.append(1)\n",
        "        else:\n",
        "            y_pred.append(0)\n",
        "\n",
        "\n",
        "    target_names= ['Not Cyberbullying', 'Cyberbullying']\n",
        "    print(confusion_matrix (y_pred, y_true))\n",
        "    print(classification_report(y_pred, y_true, target_names=target_names))\n",
        "    print(\"Accuracy: \",accuracy_score(y_pred, y_true))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "-XNx0fY_SIlP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 249
        },
        "outputId": "847a9802-dfc2-4b5e-97fe-7d6150e77050"
      },
      "source": [
        "e =50\n",
        "highest_acc = 0\n",
        "\n",
        "for i in range(20):\n",
        "    print(\"iter: \", i+1)\n",
        "    training(model,e)\n",
        "    outputs_list, labels_list = testing(model)\n",
        "\n",
        "    print(\"------------------------------\")\n",
        "    print(metrics(outputs_list,labels_list))\n",
        "    print(\"------------------------------\")\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "iter:  1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-9ef774ae10bb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"iter: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mtraining\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0moutputs_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtesting\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'training' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_6jJsbAKSIlV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = []\n",
        "for j in range(len(outputs_list)):\n",
        "        if(outputs_list[i]>=0.5):\n",
        "            y_pred.append(1)\n",
        "            print('1')\n",
        "        else:\n",
        "            y_pred.append(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l1A4UuJySIlb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "37988af0-ae38-412f-be66-1cfc8a083ce4"
      },
      "source": [
        "outputs_list[59]"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.2426064131432213e-05"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6iuo2gXhSIlf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "81790398-61bd-4321-aeff-7f1d7c2f2cf1"
      },
      "source": [
        "y_pred"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x6cjhSxeSIlk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "outputId": "00afb47a-3f35-4e6a-c89f-8040609d2a40"
      },
      "source": [
        "labels_list[0][0].item()"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-70-da2ea62084fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlabels_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: 'float' object is not subscriptable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "14W-00olSIlo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "outputId": "ea1569a0-799d-4330-aa30-3cc2b27e7b0d"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "epo = np.arange(0, 2000, 200)\n",
        "# red dashes, blue squares and green triangles\n",
        "plt.plot(epo, train_losses)\n",
        "plt.plot(epo,valid_losses)\n",
        "\n",
        "plt.show()\n",
        "\n",
        "# plt.xlabel('Epoch')\n",
        "# plt.ylabel('Loss')"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-71-7718ef28cb33>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mepo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# red dashes, blue squares and green triangles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_losses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepo\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalid_losses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_losses' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gBm709ViSIls",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(output)\n",
        "print(t)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dnVhbUoXSIlw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "  code by Tae Hwan Jung(Jeff Jung) @graykode\n",
        "'''\n",
        "\n",
        "dtype = torch.FloatTensor\n",
        "\n",
        "# Text-CNN Parameter\n",
        "embedding_size = 150 # n-gram\n",
        "sequence_length = 11\n",
        "num_classes = 2  # 0 or 1\n",
        "filter_sizes = [2, 2, 2] # n-gram window\n",
        "num_filters = 3\n",
        "\n",
        "# 3 words sentences (=sequence_length is 3)\n",
        "# sentences = [\"i love you\", \"he loves me\", \"she likes baseball\", \"i hate you\", \"sorry for that\", \"this is awful\"]\n",
        "# labels = [1, 1, 1, 0, 0, 0]  # 1 is good, 0 is not good.\n",
        "\n",
        "# word_list = \" \".join(sentences).split()\n",
        "# word_list = list(set(word_list))\n",
        "# word_dict = {w: i for i, w in enumerate(word_list)}\n",
        "# vocab_size = len(word_dict)\n",
        "\n",
        "# inputs = []\n",
        "# for sen in sentences:\n",
        "#    inputs.append(np.asarray([word_dict[n] for n in sen.split()]))\n",
        "\n",
        "# targets = []\n",
        "# for out in labels:\n",
        "#    targets.append(out) # To using Torch Softmax Loss function\n",
        "\n",
        "input_batch = Variable(torch.LongTensor(dataset_11_comment_np))\n",
        "target_batch = Variable(torch.LongTensor(dataset_11_label))\n",
        "\n",
        "\n",
        "class TextCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(TextCNN, self).__init__()\n",
        "\n",
        "        self.num_filters_total = num_filters * len(filter_sizes)\n",
        "        self.W = nn.Parameter(torch.empty(vocab_size, embedding_size).uniform_(-1, 1)).type(dtype)\n",
        "        self.Weight = nn.Parameter(torch.empty(self.num_filters_total, num_classes).uniform_(-1, 1)).type(dtype)\n",
        "        self.Bias = nn.Parameter(0.1 * torch.ones([num_classes])).type(dtype)\n",
        "\n",
        "    def forward(self, X):\n",
        "        embedded_chars = self.W[X] # [batch_size, sequence_length, sequence_length]\n",
        "        embedded_chars = embedded_chars.unsqueeze(1) # add channel(=1) [batch, channel(=1), sequence_length, embedding_size]\n",
        "\n",
        "        pooled_outputs = []\n",
        "        for filter_size in filter_sizes:\n",
        "            # conv : [input_channel(=1), output_channel(=3), (filter_height, filter_width), bias_option]\n",
        "            conv = nn.Conv2d(1, num_filters, (filter_size, embedding_size), bias=True)(embedded_chars)\n",
        "            h = F.relu(conv)\n",
        "            # mp : ((filter_height, filter_width))\n",
        "            mp = nn.MaxPool2d((sequence_length - filter_size + 1, 1))\n",
        "            # pooled : [batch_size(=6), output_height(=1), output_width(=1), output_channel(=3)]\n",
        "            pooled = mp(h).permute(0, 3, 2, 1)\n",
        "            pooled_outputs.append(pooled)\n",
        "\n",
        "        h_pool = torch.cat(pooled_outputs, len(filter_sizes)) # [batch_size(=6), output_height(=1), output_width(=1), output_channel(=3) * 3]\n",
        "        h_pool_flat = torch.reshape(h_pool, [-1, self.num_filters_total]) # [batch_size(=6), output_height * output_width * (output_channel * 3)]\n",
        "\n",
        "        model = torch.mm(h_pool_flat, self.Weight) + self.Bias # [batch_size, num_classes]\n",
        "        return model\n",
        "\n",
        "model = TextCNN()\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Training\n",
        "for epoch in range(50):\n",
        "    optimizer.zero_grad()\n",
        "    output = model(input_batch)\n",
        "\n",
        "    # output : [batch_size, num_classes], target_batch : [batch_size] (LongTensor, not one-hot)\n",
        "    loss = criterion(output, target_batch)\n",
        "    if (epoch + 1) % 10 == 0:\n",
        "        print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.6f}'.format(loss))\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "# Test\n",
        "# test_text = 'sorry hate you'\n",
        "# tests = [np.asarray([word_dict[n] for n in test_text.split()])]\n",
        "# test_batch = Variable(torch.LongTensor(tests))\n",
        "\n",
        "# # Predict\n",
        "# predict = model(test_batch).data.max(1, keepdim=True)[1]\n",
        "# if predict[0][0] == 0:\n",
        "#     print(test_text,\"is Bad Mean...\")\n",
        "# else:\n",
        "#     print(test_text,\"is Good Mean!!\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tx4TFboUSIlz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "02d620c9-133a-4b2e-97cf-324217d09aa8"
      },
      "source": [
        "model.save()"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-72-fd5dede08c85>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    574\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0;32m--> 576\u001b[0;31m             type(self).__name__, name))\n\u001b[0m\u001b[1;32m    577\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'CNN' object has no attribute 'save'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MGE5LZSQWvKA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a05e75b1-9ee4-4187-8c59-b6cfa54760bb"
      },
      "source": [
        "filename = 'finalized_model_10.sav'\n",
        "joblib.dump(model, filename)"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['finalized_model_10.sav']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0jHhkXuFXETi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import joblib"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IAuY0yUwXIIB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}